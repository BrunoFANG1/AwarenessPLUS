{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e09f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "import evaluate as evaluate\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d847dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda'\n",
    "\n",
    "batch_size = 1\n",
    "train_mask = range(50)\n",
    "model_name = 'distilbert-base-uncased'\n",
    "leaning_model_dir = './saved_models/leaning/'\n",
    "hyperpartisan_model_dir = './saved_models/hyperpartisan/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1823ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, json_file):\n",
    "        with open(json_file, 'r', encoding='utf-8') as input_file:\n",
    "            self.data = json.load(input_file)\n",
    "        self.articles = []\n",
    "        self.articles.append(self.data['match']['docs'][0]['body'][0])\n",
    "        for doc in self.data['response']['docs']:\n",
    "            self.articles.append(doc['body'][0])\n",
    "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "    def __getitem__(self, idx):\n",
    "        x_token = self.tokenizer(self.articles[idx],\n",
    "                                 padding='max_length',\n",
    "                                 max_length=512,\n",
    "                                 truncation=True,\n",
    "                                 return_tensors='pt')        \n",
    "        return {'id':x_token['input_ids'][0], 'attention_mask':x_token['attention_mask'][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2e06e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ArticleDataset(json_file='./M1_output.json')\n",
    "dataloader = DataLoader(dataset, shuffle=False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa1fe6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, acc_only=True):\n",
    "    \"\"\" Evaluate a PyTorch Model\n",
    "    :param torch.nn.Module model: the model to be evaluated\n",
    "    :param torch.utils.data.DataLoader test_dataloader: DataLoader containing testing examples\n",
    "    :param torch.device device: the device that we'll be training on\n",
    "    :param bool acc_only: return only accuracy if true, else also return ground truth and pred as tuple\n",
    "    :return accuracy (also return ground truth and pred as tuple if acc_only=False)\n",
    "    \"\"\"\n",
    "    \n",
    "    # turn model into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    #Y_true and Y_pred store for epoch\n",
    "    Y_true = []\n",
    "    Y_pred = []\n",
    "    val_acc_batch = []\n",
    "    \n",
    "    \n",
    "    val_accuracy_batch = evaluate.load('accuracy')\n",
    "    \n",
    "    label = []\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['id'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "       \n",
    "        predictions = output.logits\n",
    "        predictions = torch.argmax(predictions, dim=1)\n",
    "        label.append(predictions)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5584fcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperpartisan_model = AutoModelForSequenceClassification.from_pretrained(hyperpartisan_model_dir)\n",
    "hyperpartisan_model.to(device)\n",
    "leaning_model = AutoModelForSequenceClassification.from_pretrained(leaning_model_dir)\n",
    "leaning_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "676b7c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([3], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "leaning_predictions = evaluate_model(leaning_model, dataloader, device)\n",
    "hyperpartisan_predictions = evaluate_model(hyperpartisan_model, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a642511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_political_perspective(leaning, hyperpartisan):\n",
    "    return (leaning-1) * (hyperpartisan+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f255f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_perspectives = []\n",
    "for i in range(len(leaning_predictions)):\n",
    "    coarse_perspectives.append(int(get_political_perspective(leaning_predictions[i], hyperpartisan_predictions[i]).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1de0d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -2, 0, 0, 4, 0, -2, 2, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(coarse_perspectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81f2bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_to_hyperpartisan(label):\n",
    "#     if label == 0:\n",
    "#         return 'false'\n",
    "#     elif label == 1:\n",
    "#         return 'true'\n",
    "    \n",
    "# def label_to_leaning(label):\n",
    "#     if label == 0:\n",
    "#         return 'left'\n",
    "#     elif label == 1:\n",
    "#         return 'right'\n",
    "#     elif label == 2:\n",
    "#         return 'center'\n",
    "#     elif label == 3:\n",
    "#         return 'undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffa26c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# print(label_to_hyperpartisan(int(hyperpartisan_predictions[0].data)))\n",
    "# print(label_to_leaning(int(leaning_predictions[0].data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Political Leaning: {label_to_leaning(int(leaning_prediction[0].data))}\")\n",
    "# print(f\"Is Hyperpartisan: {label_to_hyperpartisan(int(hyperpartisan_prediction[0].data))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
